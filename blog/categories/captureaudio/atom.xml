<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: CaptureAudio | 思考的轨迹]]></title>
  <link href="http://shanewfx.github.com/blog/categories/captureaudio/atom.xml" rel="self"/>
  <link href="http://shanewfx.github.com/"/>
  <updated>2013-08-16T09:11:33+08:00</updated>
  <id>http://shanewfx.github.com/</id>
  <author>
    <name><![CDATA[Shane]]></name>
    <email><![CDATA[shanewfx@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Windows上的音频采集技术]]></title>
    <link href="http://shanewfx.github.com/blog/2013/08/14/caprure-audio-on-windows/"/>
    <updated>2013-08-14T13:56:00+08:00</updated>
    <id>http://shanewfx.github.com/blog/2013/08/14/caprure-audio-on-windows</id>
    <content type="html"><![CDATA[<p>前一段时间接到一个任务，需要采集到声卡的输出信号，以便与麦克风的输入信号进行混音。</p>

<p>之前一直没有研究过音频的相关技术，这次就顺便抽出一点时间去了解了一下Windows上采集音频的相关技术。</p>

<p>对于音频处理的技术，主要有如下几种：</p>

<ul>
<li>采集麦克风输入</li>
<li>采集声卡输出</li>
<li>将音频数据送入声卡进行播放</li>
<li>对多路音频输入进行混音处理</li>
</ul>


<!--more-->


<h3>1.Windows上音频处理的API</h3>

<p>在Windows操作系统上，常用的音频处理技术主要包括：Wave系列API函数、DirectSound、Core Audio。</p>

<p>其中，Core Audio只可以在Vista以上（包括Vista）的操作系统中才能使用，主要用来取代Wave系列API函数和DirectSound。</p>

<p>Core Audio实现的功能也比较强大，能实现对麦克风的采集、声卡输出的采集、控制声音的播放。</p>

<p>而Wave系列的API函数主要是用来实现对麦克风输入的采集（使用WaveIn系列API函数）和控制声音的播放（使用后WaveOut系列函数）。</p>

<p>DirectSound能够实现的功能估计和Wave系列API差不多，可能会更强一些（由于没有使用过DirectSound，不太肯定!）。</p>

<p>为了实现采集模块对操作系统的兼容性更好，基本上对麦克风输入的采集使用WaveIn系列API函数比较多；</p>

<p>在Windows XP系统中，没有直接提供对声卡输出进行采集的API，因此，在Windows XP要实现对声卡输出的采集会比较麻烦。
通常可选用支持混音的声卡，然后通过使用声卡的混音模块来实现采集，但并不是所有的声卡都支持混音的功能，这样的方案不具备通用性。</p>

<p>要实现通用性，可以采用虚拟声卡的方式来实现，从驱动层获取声卡的输出数据，但这种方案实现难度会比较大。</p>

<p>而在Vista以上的系统中，如Win7，则可以使用Core Audio中的API函数来实现采集声卡输出的功能。</p>

<p>对于混音模块的实现，目前基本是使用自定义的混音算法来完成功能，系统没有直接的API函数可供调用。</p>

<h3>2.使用WaveIn系列API函数实现麦克风输入采集</h3>

<p>涉及的API函数：</p>

<ul>
<li><p>waveInOpen</p>

<p>  开启音频采集设备，成功后会返回设备句柄，后续的API都需要使用该句柄</p>

<p>  调用模块需要提供一个回调函数（waveInProc），以接收采集的音频数据</p></li>
<li><p>waveInClose</p>

<p>  关闭音频采集模块</p>

<p>  成功后，由waveInOpen返回的设备句柄将不再有效
</p></li>
<li><p>waveInPrepareHeader</p>

<p>  准备音频采集数据缓存的空间</p></li>
<li><p>waveInUnprepareHeader</p>

<p>  清空音频采集的数据缓存</p></li>
<li><p>waveInAddBuffer</p>

<p>  将准备好的音频数据缓存提供给音频采集设备</p>

<p>  在调用该API之前需要先调用waveInPrepareHeader</p></li>
<li><p>waveInStart</p>

<p>  控制音频采集设备开始对音频数据的采集</p></li>
<li><p>waveInStop</p>

<p>  控制音频采集设备停止对音频数据的采集</p></li>
</ul>


<p>音频采集设备采集到音频数据后，会调用在waveInOpen中设置的回调函数。</p>

<p>其中参数包括一个消息类型，根据其消息类型就可以进行相应的操作。</p>

<p>如接收到WIM_DATA消息，则说明有新的音频数据被采集到，这样就可以根据需要来对这些音频数据进行处理。</p>

<p>（示例以后补上）</p>

<h3>3.使用Core Audio实现对声卡输出的捕捉</h3>

<p>涉及的接口有：</p>

<ul>
<li><p>IMMDeviceEnumerator</p></li>
<li><p>IMMDevice</p></li>
<li><p>IAudioClient</p></li>
<li><p>IAudioCaptureClient</p></li>
</ul>


<p>主要过程：</p>

<ul>
<li><p>创建多媒体设备枚举器(IMMDeviceEnumerator)</p></li>
<li><p>通过多媒体设备枚举器获取声卡接口(IMMDevice)</p></li>
<li><p>通过声卡接口获取声卡客户端接口(IAudioClient)</p></li>
<li><p>通过声卡客户端接口(IAudioClient)可获取声卡输出的音频参数、初始化声卡、获取声卡输出缓冲区的大小、开启/停止对声卡输出的采集</p></li>
<li><p>通过声卡采集客户端接口(IAudioCaptureClient)可获取采集的声卡输出数据，并对内部缓冲区进行控制</p></li>
</ul>


<p>（示例以后补上）</p>

<h3>4.常用的混音算法</h3>

<p>混音算法就是将多路音频输入信号根据某种规则进行运算（多路音频信号相加后做限幅处理），得到一路混合后的音频，并以此作为输出的过程。</p>

<p>我目前还做过这一块，搜索了一下基本有如下几种混音算法：</p>

<ul>
<li><p>将多路音频输入信号直接相加取和作为输出</p></li>
<li><p>将多路音频输入信号直接相加取和后，再除以混音通道数，防止溢出</p></li>
<li><p>将多路音频输入信号直接相加取和后，做Clip操作（将数据限定在最大值和最小值之间），如有溢出就设最大值</p></li>
<li><p>将多路音频输入信号直接相加取和后，做饱和处理，接近最大值时进行扭曲</p></li>
<li><p>将多路音频输入信号直接相加取和后，做归一化处理，全部乘个系数，使幅值归一化</p></li>
<li><p>将多路音频输入信号直接相加取和后，使用衰减因子限制幅值</p></li>
</ul>


<p>（完）</p>
]]></content>
  </entry>
  
</feed>
